{
 "cells": [
  {
   "cell_type": "code",
   "id": "dca569d0029e1dbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T16:44:44.534552Z",
     "start_time": "2025-02-10T16:44:44.495712Z"
    }
   },
   "source": [
    "from xml.dom.domreg import well_known_implementations\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T17:15:35.087139Z",
     "start_time": "2025-02-07T17:15:35.084605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Polygon.io API Key\n",
    "API_KEY = '2l_X1NgaJhbmxY0irf8XbrlrRF4Y_cy4'\n",
    "df_1min = None\n",
    "df_15min = None\n",
    "df_1day = None\n"
   ],
   "id": "ad45f7237f79a017",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T17:15:35.137426Z",
     "start_time": "2025-02-07T17:15:35.133119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to fetch data from Polygon.io\n",
    "def fetch_data(symbol, start_date, end_date):\n",
    "    url = f'https://api.polygon.io/v2/aggs/ticker/{symbol}/range/1/minute/{start_date}/{end_date}'\n",
    "    params = {\n",
    "        'adjusted': 'false',  # Adjusted for splits/dividends\n",
    "        'sort': 'asc',\n",
    "        'limit': 50000,  # Max data points per call\n",
    "        'apiKey': API_KEY\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    if 'results' in data:\n",
    "        return data['results']\n",
    "    else:\n",
    "        return []\n"
   ],
   "id": "c6154a2d2b14e93a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T17:15:35.151503Z",
     "start_time": "2025-02-07T17:15:35.147503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert timestamp to human-readable datetime\n",
    "def convert_timestamp(ts):\n",
    "    return datetime.utcfromtimestamp(ts / 1000) # the time from polygon.io is in milliseconds"
   ],
   "id": "740900c42e255079",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T17:15:35.212043Z",
     "start_time": "2025-02-07T17:15:35.200309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to check data completeness\n",
    "# this function doesn't currently do anything OTHER THAN check id data is EMPTY\n",
    "def is_data_complete(data, start_time, end_time):\n",
    "    if not data:\n",
    "        print(\"Warning: No data received!\")\n",
    "        return False\n",
    "\n",
    "    # Convert timestamps to minute-based list\n",
    "    received_timestamps = {datetime.utcfromtimestamp(d['t'] / 1000) for d in data}\n",
    "\n",
    "    # Generate expected timestamps\n",
    "    expected_timestamps = set()\n",
    "    current_time = start_time\n",
    "    while current_time <= end_time:\n",
    "        expected_timestamps.add(current_time)\n",
    "        current_time += timedelta(minutes=1)\n",
    "\n",
    "    # Compare expected vs. received timestamps\n",
    "    missing = expected_timestamps - received_timestamps #Note sufficient as this include non market day and times as well.\n",
    "\n",
    "    # Condition for checking if data is complete.\n",
    "    # if missing:\n",
    "    #     print(f\"Warning: {len(missing)} missing minutes of data.\")\n",
    "    #     return False\n",
    "\n",
    "    return True"
   ],
   "id": "c0f3dd1f4e018a8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T17:15:35.237034Z",
     "start_time": "2025-02-07T17:15:35.229197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aggregate minute data into daily OHLCV\n",
    "def aggregate_daily(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    df['timestamp'] = df['t'].apply(convert_timestamp)\n",
    "\n",
    "    # Convert timestamp to date (removing time)\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "\n",
    "    # Group by date and calculate daily OHLCV\n",
    "    daily_data = df.groupby('date').agg(\n",
    "        open=('o', 'first'),\n",
    "        high=('h', 'max'),\n",
    "        low=('l', 'min'),\n",
    "        close=('c', 'last'),\n",
    "        volume=('v', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    return daily_data\n"
   ],
   "id": "f406f9e8251a3657",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T17:15:35.290303Z",
     "start_time": "2025-02-07T17:15:35.276661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main function to fetch data and create the plot\n",
    "def create_daily_candlestick_plot():\n",
    "    symbol = 'AAPL'\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=90)  # 3 months back\n",
    "\n",
    "    # Convert dates to string format\n",
    "    start_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    \"\"\"\n",
    "    UNCOMMENT THE ONE OF THE BELOW CODEs to directly fetch data from Polygon.io OR USE glovally saved dataand create the plot\n",
    "    ## In future change the fetch_data function to also recieve the multiplier and timespan as well so that we don't have to manually change it\n",
    "\n",
    "    NOTE ADDITIONAL CHANGES:\n",
    "    - Uncomment the right daily-data assigned code\n",
    "    \"\"\"\n",
    "    # Fetch data from Polygon.io\n",
    "    data = fetch_data(symbol, start_str, end_str)\n",
    "\n",
    "    # # Fetch data from the global variable\n",
    "    # ## IN FUTURE; set it up so that we can set the duration of data to be plotted\n",
    "    # data = df_SPY_1day\n",
    "    # # Convert timestamp to date (removing time)\n",
    "    # data['date'] = data['timestamp'].dt.date\n",
    "\n",
    "    # Check if data was received\n",
    "    if not data:\n",
    "        print(\"No data received\")\n",
    "        return\n",
    "\n",
    "    # Aggregate the minute data into daily data\n",
    "    ## UNCOMMENT ONE OF THE CODES BELOW\n",
    "    # daily_data = aggregate_daily(data)\n",
    "    df = pd.DataFrame(data)\n",
    "    df['timestamp'] = df['t'].apply(convert_timestamp)\n",
    "\n",
    "    # Convert timestamp to date (removing time)\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    daily_data = df.rename(columns={'o': 'open', 'h': 'high', 'l': 'low', 'c': 'close', 'v': 'volume'})\n",
    "\n",
    "\n",
    "    # UNCOMMENT 1ST ONE IF use fetch_data, IF NOT THEN UNCOMMENT THE 2ND ONE\n",
    "    # Create the candlestick chart using Plotly\n",
    "    fig = go.Figure(data=[go.Candlestick(x=daily_data['date'],\n",
    "                                         open=daily_data['open'],\n",
    "                                         high=daily_data['high'],\n",
    "                                         low=daily_data['low'],\n",
    "                                         close=daily_data['close'])])\n",
    "\n",
    "    # # Create the candlestick chart using Plotly\n",
    "    # fig = go.Figure(data=[go.Candlestick(x=daily_data['date'],\n",
    "    #                                      open=daily_data['o'],\n",
    "    #                                      high=daily_data['h'],\n",
    "    #                                      low=daily_data['l'],\n",
    "    #                                      close=daily_data['c'])])\n",
    "\n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        title=f'SPY Candlestick Chart for 2 yaers (Daily)', # may add this if needed; for Last 3 Months\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Price (USD)',\n",
    "        xaxis_rangeslider_visible=False,  # Disable range slider\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    print(f\"\\n Plotting data for 2 year using 1 day data)\")\n",
    "    fig.show()\n",
    "\n",
    "    # save the graph to a file\n",
    "    fig.write_image('daily_candlestick_plot.png')"
   ],
   "id": "1ac7b7eb65f2848d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T17:15:35.333559Z",
     "start_time": "2025-02-07T17:15:35.317652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main function to collect data and save to Excel\n",
    "def main():\n",
    "    symbol = 'SPY'\n",
    "\n",
    "    # Set the tick length of the returned data\n",
    "    multiplier_timespan = 1\n",
    "    timespan_tick = 'minute' # 'day' or 'minute' PLEASE READ THE BELOW NOTE....\n",
    "    duration_days = 7 # total duration in minutes\n",
    "    \"\"\"\n",
    "    When changing the minute or day, make sure to change the following variables as well;\n",
    "    - timespan_tick\n",
    "    - change felch_data api call to say minute or day\n",
    "    - chage which global variable we are calling such as \" global df_SPY_*\n",
    "    - change the df_SPY_* variable at the end to save the data to the correct global variable\n",
    "    - change the excel file name appropriately\n",
    "    \"\"\"\n",
    "\n",
    "    end_date = datetime.now() - timedelta(days=1) #Yesterday because the historical data from Polygon.io is 1 day behind as it id End-of-Day data for Free basic tier\n",
    "\n",
    "    # start_date = end_date - timedelta(days=2*365)  # 2 years back\n",
    "    # start_date = end_date - timedelta(days=90)  # 90 days\n",
    "    start_date = end_date - timedelta(days=duration_days)  # 7 days\n",
    "\n",
    "    # Split data into 2-month chunks (12 API calls for 2 years) for 'x' minute data (any no of x minutes)\n",
    "    # Don't split data for end of day data\n",
    "    num_calls = 1 if timespan_tick == 'minute' else 1\n",
    "\n",
    "    delta = (end_date - start_date) / num_calls\n",
    "    date_ranges = [(start_date + i*delta, start_date + (i+1)*delta) for i in range(num_calls)]\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for i, (start, end) in enumerate(date_ranges):\n",
    "        start_str = start.strftime('%Y-%m-%d')\n",
    "        end_str = end.strftime('%Y-%m-%d')\n",
    "        print(f\"\\nFetching data from {start_str} to {end_str} (API call {i+1}/{num_calls})\")\n",
    "\n",
    "        data = fetch_data(symbol, start_str, end_str)\n",
    "        all_data.extend(data)\n",
    "\n",
    "        # Validate completeness before adding\n",
    "        if is_data_complete(data, start, end):\n",
    "            print(f\"Adding Data from API call {i+1}/{num_calls} to complete data set\")\n",
    "            all_data.extend(data)\n",
    "        else:\n",
    "            print(f\"Data incomplete for {start_str} to {end_str}, skipping...\")\n",
    "\n",
    "        # Enforce rate limit: Wait 15 seconds after *every* API call\n",
    "        if i < num_calls - 1:  # Avoid sleeping after the last call\n",
    "            print(\"Waiting 15 seconds to respect rate limit...\")\n",
    "            time.sleep(15)\n",
    "\n",
    "    # Convert data to DataFrame\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df['timestamp'] = df['t'].apply(convert_timestamp)\n",
    "    df = df[['timestamp', 'o', 'h', 'l', 'c', 'v']]  # Keep relevant columns\n",
    "\n",
    "    # add values to all the global variable for later access\n",
    "    global df_1min\n",
    "    df_1min = df\n",
    "\n",
    " # Save to Excel\n",
    "    df.to_excel(f'data/generated_data/{symbol}_Historical_Data_polygon_{multiplier_timespan}{timespan_tick}_dur{duration_days}d_{start_str}_to_{end_str}.xlsx', index=False)\n",
    "    print(f\"\\nData saved to {symbol}_Historical_Data_polygon_{multiplier_timespan}{timespan_tick}_dur{duration_days}d_{start_str}_to_{end_str}.xlsx\")\n"
   ],
   "id": "b9fa626199b2149e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-02-07T17:15:36.821621Z",
     "start_time": "2025-02-07T17:15:35.408605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data from 2025-01-30 to 2025-02-06 (API call 1/1)\n",
      "Adding Data from API call 1/1 to complete data set\n",
      "\n",
      "Data saved to SPY_Historical_Data_polygon_1minute_dur7d_2025-01-30_to_2025-02-06.xlsx\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "b6c748e1ef8d2c58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T17:15:36.828272Z",
     "start_time": "2025-02-07T17:15:36.825403Z"
    }
   },
   "source": [
    "# create_daily_candlestick_plot()\n",
    "\n",
    "# daily_data = df_SPY_1day\n",
    "# daily_data['date'] = daily_data['timestamp'].dt.date\n",
    "#\n",
    "# fig = go.Figure(data=[go.Candlestick(x=daily_data['date'],\n",
    "#                                          open=daily_data['o'],\n",
    "#                                          high=daily_data['h'],\n",
    "#                                          low=daily_data['l'],\n",
    "#                                          close=daily_data['c'])])\n",
    "#\n",
    "# # save the graph to a file\n",
    "# fig.write_image('daily_candlestick_plot.png')\n",
    "#\n",
    "# print(f\"\\n Plotting data for 2 year using 1 day data)\")\n",
    "# fig.show()\n"
   ],
   "outputs": [],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python CSCE5720",
   "language": "python",
   "name": "csce5720"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
